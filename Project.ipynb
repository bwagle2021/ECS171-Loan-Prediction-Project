{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "054bc7b1",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35230bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
      "0  LP001002   Male      No          0      Graduate            No   \n",
      "1  LP001003   Male     Yes          1      Graduate            No   \n",
      "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
      "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
      "4  LP001008   Male      No          0      Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5849                0.0         NaN             360.0   \n",
      "1             4583             1508.0       128.0             360.0   \n",
      "2             3000                0.0        66.0             360.0   \n",
      "3             2583             2358.0       120.0             360.0   \n",
      "4             6000                0.0       141.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area Loan_Status  \n",
      "0             1.0         Urban           Y  \n",
      "1             1.0         Rural           N  \n",
      "2             1.0         Urban           Y  \n",
      "3             1.0         Urban           Y  \n",
      "4             1.0         Urban           Y  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "trainingDf = pd.read_csv('./train_dataset.csv.xls')\n",
    "\n",
    "print(trainingDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c8a9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============COLUMNS WITH EMPTY VALUE=============\n",
      "['Gender', 'Married', 'Dependents', 'Self_Employed', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n"
     ]
    }
   ],
   "source": [
    "print(\"============COLUMNS WITH EMPTY VALUE=============\")\n",
    "print(trainingDf.columns[trainingDf.isna().any()].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da4ac8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping loan_id\n",
    "trainingDf = trainingDf.drop(columns=['Loan_ID'])\n",
    "\n",
    "#Populating rows with null data with default values\n",
    "trainingDf['Gender'] = trainingDf['Gender'].fillna('unknown')\n",
    "trainingDf['Married'] = trainingDf['Married'].fillna('unknown')\n",
    "trainingDf['Self_Employed'] = trainingDf['Self_Employed'].fillna('unknown')\n",
    "trainingDf['Dependents'] = trainingDf['Dependents'].fillna(0)\n",
    "\n",
    "#Dropping rows with empty values for following columns 'LoanAmount', 'Loan_Amount_Term', 'Credit_History'\n",
    "trainingDf = trainingDf[trainingDf['LoanAmount'].notna()]\n",
    "trainingDf = trainingDf[trainingDf['Loan_Amount_Term'].notna()]\n",
    "trainingDf = trainingDf[trainingDf['Credit_History'].notna()]\n",
    "\n",
    "trainingDf['Dependents'].replace(\n",
    "    to_replace=['3+'],\n",
    "    value='4',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f21c7773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============COLUMNS WITH EMPTY VALUE=============\n",
      "[]\n",
      "Remaining rows after dropping data: 529\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"============COLUMNS WITH EMPTY VALUE=============\")\n",
    "print(trainingDf.columns[trainingDf.isna().any()].tolist())\n",
    "print(\"Remaining rows after dropping data:\", len(trainingDf.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6885d200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============UNIQUE VALUE FOR CATEGORICAL DATA=============\n",
      "Gender:  ['Male' 'Female' 'unknown']\n",
      "Married:  ['Yes' 'No' 'unknown']\n",
      "Education:  ['Graduate' 'Not Graduate']\n",
      "Self_Employed:  ['No' 'Yes' 'unknown']\n",
      "Property_Area:  ['Rural' 'Urban' 'Semiurban']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"============UNIQUE VALUE FOR CATEGORICAL DATA=============\")\n",
    "print(\"Gender: \", trainingDf['Gender'].unique())\n",
    "print(\"Married: \", trainingDf['Married'].unique())\n",
    "print(\"Education: \", trainingDf['Education'].unique())\n",
    "print(\"Self_Employed: \", trainingDf['Self_Employed'].unique())\n",
    "print(\"Property_Area: \", trainingDf['Property_Area'].unique())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1afbf02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Gender Married Dependents     Education Self_Employed  ApplicantIncome  \\\n",
      "330    Male      No          1      Graduate            No             4384   \n",
      "410  Female      No          1  Not Graduate           Yes             3867   \n",
      "217    Male     Yes          0      Graduate            No             3727   \n",
      "143    Male     Yes          0      Graduate            No             2698   \n",
      "525    Male     Yes          2      Graduate           Yes            17500   \n",
      "\n",
      "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
      "330             1793.0       117.0             360.0             1.0   \n",
      "410                0.0        62.0             360.0             1.0   \n",
      "217             1775.0       131.0             360.0             1.0   \n",
      "143             2034.0       122.0             360.0             1.0   \n",
      "525                0.0       400.0             360.0             1.0   \n",
      "\n",
      "    Property_Area Loan_Status  \n",
      "330         Urban           Y  \n",
      "410     Semiurban           N  \n",
      "217     Semiurban           Y  \n",
      "143     Semiurban           Y  \n",
      "525         Rural           Y  \n",
      "    Dependents  ApplicantIncome  CoapplicantIncome  LoanAmount  \\\n",
      "330          1             4384             1793.0       117.0   \n",
      "410          1             3867                0.0        62.0   \n",
      "217          0             3727             1775.0       131.0   \n",
      "143          0             2698             2034.0       122.0   \n",
      "525          2            17500                0.0       400.0   \n",
      "\n",
      "     Loan_Amount_Term  Credit_History  \n",
      "330             360.0             1.0  \n",
      "410             360.0             1.0  \n",
      "217             360.0             1.0  \n",
      "143             360.0             1.0  \n",
      "525             360.0             1.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train, test = train_test_split(trainingDf, test_size=0.2, random_state=23)\n",
    "print(train.head())\n",
    "X_train, y_train = train.copy().drop(columns=['Loan_Status']), train['Loan_Status']\n",
    "X_test, y_test = test.copy().drop(columns=['Loan_Status']), test['Loan_Status']\n",
    "\n",
    "Categorical_columns = [\"Gender\", \"Married\", \"Education\", \"Self_Employed\", \"Property_Area\"]\n",
    "Numerical_columns = [\"Dependents\", \"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"]\n",
    "\n",
    "Categorical_X_train = X_train[Categorical_columns]\n",
    "Categorical_X_test = X_test[Categorical_columns]\n",
    "\n",
    "Numerical_X_train = X_train[Numerical_columns]\n",
    "Numerical_X_test = X_test[Numerical_columns]\n",
    "\n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit(Categorical_X_train)\n",
    "Categorical_X_train_encoded = encoder.transform(Categorical_X_train).toarray()\n",
    "Categorical_X_test_encoded = encoder.transform(Categorical_X_test).toarray()\n",
    "\n",
    "print(Numerical_X_train.head())\n",
    "\n",
    "standard_Scaler = preprocessing.MinMaxScaler()\n",
    "standard_Scaler.fit(Numerical_X_train)\n",
    "Numerical_X_train_encoded = standard_Scaler.transform(Numerical_X_train)\n",
    "Numerical_X_test_encoded = standard_Scaler.transform(Numerical_X_test)\n",
    "\n",
    "y_encoder = preprocessing.LabelEncoder()\n",
    "y_encoder.fit(y_train)\n",
    "Y_train_encoded = y_encoder.transform(y_train)\n",
    "Y_test_encoded = y_encoder.transform(y_test)\n",
    "\n",
    "Combined_X_train_encoded = np.concatenate((Categorical_X_train_encoded, Numerical_X_train_encoded), axis=1)\n",
    "#print(Combined_X_train_encoded)\n",
    "Combined_X_test_encoded = np.concatenate((Categorical_X_test_encoded, Numerical_X_test_encoded), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57def8a0",
   "metadata": {},
   "source": [
    "### 1) Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e24e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============LOGISTIC REGRESSION MODEL=============\n",
      "Accuracy is  0.8207547169811321\n",
      "Mean Square Error :  0.1792452830188679\n",
      "[[23  0]\n",
      " [19 64]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71        42\n",
      "           1       0.77      1.00      0.87        64\n",
      "\n",
      "    accuracy                           0.82       106\n",
      "   macro avg       0.89      0.77      0.79       106\n",
      "weighted avg       0.86      0.82      0.81       106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"============LOGISTIC REGRESSION MODEL=============\")\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(Combined_X_train_encoded,Y_train_encoded)\n",
    "y_predicted = lr_model.predict(Combined_X_test_encoded)\n",
    "print(\"Accuracy is \", accuracy_score(y_predicted,Y_test_encoded))\n",
    "print(\"Mean Square Error : \", mean_squared_error(Y_test_encoded, y_predicted))\n",
    "print(confusion_matrix(y_predicted,Y_test_encoded))\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(Y_test_encoded, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2321f51",
   "metadata": {},
   "source": [
    "### 2) 10-fold cross validation to generalize the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aee014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============LOGISTIC REGRESSION MODEL USING 10-FOLD CROSS VALIDATION=============\n",
      "Accuracy for batch  1  :  0.7735849056603774\n",
      "Mean Square Error for batch  1  :  0.22641509433962265\n",
      "Accuracy for batch  2  :  0.8490566037735849\n",
      "Mean Square Error for batch  2  :  0.1509433962264151\n",
      "Accuracy for batch  3  :  0.7547169811320755\n",
      "Mean Square Error for batch  3  :  0.24528301886792453\n",
      "Accuracy for batch  4  :  0.7735849056603774\n",
      "Mean Square Error for batch  4  :  0.22641509433962265\n",
      "Accuracy for batch  5  :  0.8301886792452831\n",
      "Mean Square Error for batch  5  :  0.16981132075471697\n",
      "Accuracy for batch  6  :  0.7547169811320755\n",
      "Mean Square Error for batch  6  :  0.24528301886792453\n",
      "Accuracy for batch  7  :  0.8490566037735849\n",
      "Mean Square Error for batch  7  :  0.1509433962264151\n",
      "Accuracy for batch  8  :  0.8679245283018868\n",
      "Mean Square Error for batch  8  :  0.1320754716981132\n",
      "Accuracy for batch  9  :  0.8301886792452831\n",
      "Mean Square Error for batch  9  :  0.16981132075471697\n",
      "Accuracy for batch  10  :  0.8653846153846154\n",
      "Mean Square Error for batch  10  :  0.1346153846153846\n"
     ]
    }
   ],
   "source": [
    "# To find list of accuracy and MSE values of the model using K-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "print(\"============LOGISTIC REGRESSION MODEL USING 10-FOLD CROSS VALIDATION=============\")\n",
    "kf = KFold(n_splits=10)\n",
    "X = trainingDf.copy().drop(columns=['Loan_Status'])\n",
    "y = trainingDf['Loan_Status']\n",
    "\n",
    "#re-split the processed data into X and y then encode before doing 10-cross validation\n",
    "Categorical_X = X[Categorical_columns]\n",
    "#print(Categorical_X)\n",
    "Numerical_X = X[Numerical_columns]\n",
    "\n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit(Categorical_X)\n",
    "Categorical_X_encoded = encoder.transform(Categorical_X).toarray()\n",
    "\n",
    "#print(Categorical_X_encoded)\n",
    "\n",
    "standard_Scaler.fit(Numerical_X)\n",
    "Numerical_X_encoded = standard_Scaler.transform(Numerical_X)\n",
    "#print(Numerical_X_encoded)\n",
    "\n",
    "y_encoder.fit(y)\n",
    "Y_encoded = y_encoder.transform(y)\n",
    "\n",
    "Combined_X_encoded = np.concatenate((Categorical_X_encoded, Numerical_X_encoded), axis=1)\n",
    "\n",
    "#print(Combined_X_encoded)\n",
    "\n",
    "idx = 0\n",
    "for train_indices, test_indices in kf.split(Combined_X_encoded):\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\n",
    "    \n",
    "    lr_model.fit(Combined_X_encoded[start_train:stop_train], Y_encoded[start_train:stop_train])\n",
    "    pred = lr_model.predict(Combined_X_encoded[start_test:stop_test])\n",
    "\n",
    "    idx+=1\n",
    "    print(\"Accuracy for batch \", idx, \" : \", accuracy_score(Y_encoded[start_test:stop_test], pred))\n",
    "    print(\"Mean Square Error for batch \", idx, \" : \", mean_squared_error(Y_encoded[start_test:stop_test], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d00b2a",
   "metadata": {},
   "source": [
    "### 3) Naïve Bayes Classifier for Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fa006c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============NAIVE BAYES CLASSIFIER FOR NUMERICAL ATTRIBUTES=============\n",
      "Classification report for train datasets:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.47      0.58       121\n",
      "           1       0.82      0.94      0.88       302\n",
      "\n",
      "    accuracy                           0.81       423\n",
      "   macro avg       0.79      0.71      0.73       423\n",
      "weighted avg       0.80      0.81      0.79       423\n",
      "\n",
      "***************************************************************************\n",
      "Classification report for test datasets:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.55      0.69        42\n",
      "           1       0.77      0.97      0.86        64\n",
      "\n",
      "    accuracy                           0.80       106\n",
      "   macro avg       0.84      0.76      0.77       106\n",
      "weighted avg       0.83      0.80      0.79       106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calssify using Naive Bayes for numerical attributes \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(\"============NAIVE BAYES CLASSIFIER FOR NUMERICAL ATTRIBUTES=============\")\n",
    "\n",
    "GNB = GaussianNB()\n",
    "\n",
    "GNB.fit(Numerical_X_train_encoded, Y_train_encoded)\n",
    "\n",
    "print(\"Classification report for train datasets:\")\n",
    "print(classification_report(Y_train_encoded, GNB.predict(Numerical_X_train_encoded)))\n",
    "print(\"***************************************************************************\")\n",
    "print(\"Classification report for test datasets:\")\n",
    "print(classification_report(Y_test_encoded, GNB.predict(Numerical_X_test_encoded)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb30452",
   "metadata": {},
   "source": [
    "### 4) 10-fold cross validation to generalize the Naïve Bayes Classifier for Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a060dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============NAIVE BAYES CLASSIFIER FOR NUMERICAL ATTRIBUTES USING 10-FOLD CROSS VALIDATION=============\n",
      "Accuracy for batch  1  :  0.7547169811320755\n",
      "Mean Square Error for batch  1  :  0.24528301886792453\n",
      "Accuracy for batch  2  :  0.8490566037735849\n",
      "Mean Square Error for batch  2  :  0.1509433962264151\n",
      "Accuracy for batch  3  :  0.7547169811320755\n",
      "Mean Square Error for batch  3  :  0.24528301886792453\n",
      "Accuracy for batch  4  :  0.7547169811320755\n",
      "Mean Square Error for batch  4  :  0.24528301886792453\n",
      "Accuracy for batch  5  :  0.8113207547169812\n",
      "Mean Square Error for batch  5  :  0.18867924528301888\n",
      "Accuracy for batch  6  :  0.7547169811320755\n",
      "Mean Square Error for batch  6  :  0.24528301886792453\n",
      "Accuracy for batch  7  :  0.8301886792452831\n",
      "Mean Square Error for batch  7  :  0.16981132075471697\n",
      "Accuracy for batch  8  :  0.8490566037735849\n",
      "Mean Square Error for batch  8  :  0.1509433962264151\n",
      "Accuracy for batch  9  :  0.8113207547169812\n",
      "Mean Square Error for batch  9  :  0.18867924528301888\n",
      "Accuracy for batch  10  :  0.8461538461538461\n",
      "Mean Square Error for batch  10  :  0.15384615384615385\n"
     ]
    }
   ],
   "source": [
    "# To find list of accuracy and MSE values of the model using K-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "print(\"============NAIVE BAYES CLASSIFIER FOR NUMERICAL ATTRIBUTES USING 10-FOLD CROSS VALIDATION=============\")\n",
    "\n",
    "idx = 0\n",
    "for train_indices, test_indices in kf.split(Numerical_X_encoded):\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\n",
    "    \n",
    "    GNB.fit(Numerical_X_encoded[start_train:stop_train], Y_encoded[start_train:stop_train])\n",
    "    pred = GNB.predict(Numerical_X_encoded[start_test:stop_test])\n",
    "\n",
    "    idx+=1\n",
    "    print(\"Accuracy for batch \", idx, \" : \", accuracy_score(Y_encoded[start_test:stop_test], pred))\n",
    "    print(\"Mean Square Error for batch \", idx, \" : \", mean_squared_error(Y_encoded[start_test:stop_test], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754db29",
   "metadata": {},
   "source": [
    "### 5) Naïve Bayes Classifier for Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ac44f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============NAIVE BAYES CLASSIFIER FOR CATEGORICAL ATTRIBUTES=============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.19      0.27        42\n",
      "           1       0.62      0.86      0.72        64\n",
      "\n",
      "    accuracy                           0.59       106\n",
      "   macro avg       0.54      0.52      0.50       106\n",
      "weighted avg       0.56      0.59      0.54       106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "print(\"============NAIVE BAYES CLASSIFIER FOR CATEGORICAL ATTRIBUTES=============\")\n",
    "\n",
    "NB = CategoricalNB() \n",
    "\n",
    "NB.fit(Categorical_X_train_encoded, Y_train_encoded)\n",
    "print(classification_report(Y_test_encoded, NB.predict(Categorical_X_test_encoded)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717653ef",
   "metadata": {},
   "source": [
    "### 6) 10-fold cross validation to generalize the Naïve Bayes Classifier for Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73ce6098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============NAIVE BAYES CLASSIFIER FOR CATEGORICAL ATTRIBUTES USING 10-FOLD CROSS VALIDATION=============\n",
      "Accuracy for batch  1  :  0.41509433962264153\n",
      "Mean Square Error for batch  1  :  0.5849056603773585\n",
      "Accuracy for batch  2  :  0.2830188679245283\n",
      "Mean Square Error for batch  2  :  0.7169811320754716\n",
      "Accuracy for batch  3  :  0.41509433962264153\n",
      "Mean Square Error for batch  3  :  0.5849056603773585\n",
      "Accuracy for batch  4  :  0.2830188679245283\n",
      "Mean Square Error for batch  4  :  0.7169811320754716\n",
      "Accuracy for batch  5  :  0.3018867924528302\n",
      "Mean Square Error for batch  5  :  0.6981132075471698\n",
      "Accuracy for batch  6  :  0.3584905660377358\n",
      "Mean Square Error for batch  6  :  0.6415094339622641\n",
      "Accuracy for batch  7  :  0.37735849056603776\n",
      "Mean Square Error for batch  7  :  0.6226415094339622\n",
      "Accuracy for batch  8  :  0.33962264150943394\n",
      "Mean Square Error for batch  8  :  0.660377358490566\n",
      "Accuracy for batch  9  :  0.32075471698113206\n",
      "Mean Square Error for batch  9  :  0.6792452830188679\n",
      "Accuracy for batch  10  :  0.34615384615384615\n",
      "Mean Square Error for batch  10  :  0.6538461538461539\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "print(\"============NAIVE BAYES CLASSIFIER FOR CATEGORICAL ATTRIBUTES USING 10-FOLD CROSS VALIDATION=============\")\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "idx = 0\n",
    "for train_indices, test_indices in kf.split(Categorical_X_encoded):\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\n",
    "    \n",
    "    GNB.fit(Categorical_X_encoded[start_train:stop_train], Y_encoded[start_train:stop_train])\n",
    "    pred = GNB.predict(Categorical_X_encoded[start_test:stop_test])\n",
    "\n",
    "    idx+=1\n",
    "    print(\"Accuracy for batch \", idx, \" : \", accuracy_score(Y_encoded[start_test:stop_test], pred))\n",
    "    print(\"Mean Square Error for batch \", idx, \" : \", mean_squared_error(Y_encoded[start_test:stop_test], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ce095",
   "metadata": {},
   "source": [
    "## Testing\n",
    "1. Test the models using the provided testing data. Treat the provided testing data as real life scenarios.\n",
    "\n",
    "The provide testing dataset does not have 'Loan_Status'.  :( \\\n",
    "Just for right now, I will assume all cases in there are approved cases, and see how it go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c57ddb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
      "0  LP001015   Male     Yes          0      Graduate            No   \n",
      "1  LP001022   Male     Yes          1      Graduate            No   \n",
      "2  LP001031   Male     Yes          2      Graduate            No   \n",
      "3  LP001035   Male     Yes          2      Graduate            No   \n",
      "4  LP001051   Male      No          0  Not Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5720                  0       110.0             360.0   \n",
      "1             3076               1500       126.0             360.0   \n",
      "2             5000               1800       208.0             360.0   \n",
      "3             2340               2546       100.0             360.0   \n",
      "4             3276                  0        78.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area  \n",
      "0             1.0         Urban  \n",
      "1             1.0         Urban  \n",
      "2             1.0         Urban  \n",
      "3             NaN         Urban  \n",
      "4             1.0         Urban  \n",
      "Columns with empty value in the Testing data:\n",
      "['Gender', 'Dependents', 'Self_Employed', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n",
      "\n",
      "Testing Data:\n",
      "  Gender Married Dependents     Education Self_Employed  ApplicantIncome  \\\n",
      "0   Male     Yes          0      Graduate            No             5720   \n",
      "1   Male     Yes          1      Graduate            No             3076   \n",
      "2   Male     Yes          2      Graduate            No             5000   \n",
      "4   Male      No          0  Not Graduate            No             3276   \n",
      "5   Male     Yes          0  Not Graduate           Yes             2165   \n",
      "\n",
      "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
      "0                  0       110.0             360.0             1.0   \n",
      "1               1500       126.0             360.0             1.0   \n",
      "2               1800       208.0             360.0             1.0   \n",
      "4                  0        78.0             360.0             1.0   \n",
      "5               3422       152.0             360.0             1.0   \n",
      "\n",
      "  Property_Area Loan_Status  \n",
      "0         Urban           Y  \n",
      "1         Urban           Y  \n",
      "2         Urban           Y  \n",
      "4         Urban           Y  \n",
      "5         Urban           Y  \n",
      "\n",
      "Remaining rows in testing data after dropping: 328\n"
     ]
    }
   ],
   "source": [
    "# Load the testing data\n",
    "testingDF = pd.read_csv('./test_Y3wMUE5_7gLdaTN.csv.xls')\n",
    "print(testingDF.head())\n",
    "\n",
    "# Check the provided testing data and do some processing if necessary\n",
    "print(\"Columns with empty value in the Testing data:\")\n",
    "print(testingDF.columns[testingDF.isna().any()].tolist())\n",
    "\n",
    "testingDF = testingDF.drop(columns=['Loan_ID'])\n",
    "testingDF['Gender'] = testingDF['Gender'].fillna('unknown')\n",
    "testingDF['Self_Employed'] = testingDF['Self_Employed'].fillna('unknown')\n",
    "testingDF['Dependents'] = testingDF['Dependents'].fillna(0)\n",
    "\n",
    "testingDF['Dependents'].replace(\n",
    "    to_replace=['3+'],\n",
    "    value='4',\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "testingDF = testingDF[testingDF['LoanAmount'].notna()]\n",
    "testingDF = testingDF[testingDF['Loan_Amount_Term'].notna()]\n",
    "testingDF = testingDF[testingDF['Credit_History'].notna()]\n",
    "\n",
    "testingDF['Loan_Status'] = 'Y'  # A bad assumption, but I will see how it go. \n",
    "\n",
    "print(\"\\nTesting Data:\")\n",
    "print(testingDF.head())\n",
    "\n",
    "print(\"\\nRemaining rows in testing data after dropping:\", len(testingDF.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ccaf2",
   "metadata": {},
   "source": [
    "2. Currently we had 3 models trained:\n",
    "- Logistic regression model -- 'lr_mode', \n",
    "- Gaussian Naive Bayes -- 'GNB', \n",
    "- Naive Bayes classifier for categorical features -- 'NB'. \n",
    "\n",
    "We will evuluate these models using the testing data set.\n",
    "There will be warning because our y only have 1 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c65eac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic regression model:\n",
      "Accuracy is  0.823170731707317\n",
      "Mean Square Error :  0.17682926829268292\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.82      0.90       328\n",
      "\n",
      "    accuracy                           0.82       328\n",
      "   macro avg       0.50      0.41      0.45       328\n",
      "weighted avg       1.00      0.82      0.90       328\n",
      "\n",
      "\n",
      "Naive Bayes classifier for categorical features:\n",
      "Accuracy is  0.850609756097561\n",
      "Mean Square Error :  0.14939024390243902\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.85      0.92       328\n",
      "\n",
      "    accuracy                           0.85       328\n",
      "   macro avg       0.50      0.43      0.46       328\n",
      "weighted avg       1.00      0.85      0.92       328\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hblei/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hblei/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hblei/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hblei/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hblei/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hblei/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_X, test_y = testingDF.copy().drop(columns=['Loan_Status']), testingDF['Loan_Status']\n",
    "test_categorical = testingDF[Categorical_columns]\n",
    "test_numerical = testingDF[Numerical_columns]\n",
    "\n",
    "# use the same encoders from previous, and in the same format\n",
    "test_y_encoded = y_encoder.transform(test_y)\n",
    "test_categorical_encoded = encoder.transform(test_categorical).toarray()\n",
    "test_numerical_encoded = standard_Scaler.transform(test_numerical)\n",
    "test_X_combined = np.concatenate((test_categorical_encoded, test_numerical_encoded), axis=1)\n",
    "\n",
    "print(\"\\nLogistic regression model:\")\n",
    "y_predicted_logistic = lr_model.predict(test_X_combined)\n",
    "print(\"Accuracy is \", accuracy_score(y_predicted_logistic,test_y_encoded))\n",
    "print(\"Mean Square Error : \", mean_squared_error(test_y_encoded, y_predicted_logistic))\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(test_y_encoded, y_predicted_logistic)) \n",
    "\n",
    "print(\"\\nNaive Bayes classifier for categorical features:\")\n",
    "print(\"Accuracy is \", accuracy_score(NB.predict(test_categorical_encoded),test_y_encoded))\n",
    "print(\"Mean Square Error : \", mean_squared_error(test_y_encoded, NB.predict(test_categorical_encoded)))\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(test_y_encoded, NB.predict(test_categorical_encoded))) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7cae688b6d5c7886c97c16c08b8426e0c75b8da6e1119f020936594eaecaf1a0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
