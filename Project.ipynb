{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn import preprocessing\r\n",
    "\r\n",
    "trainingDf = pd.read_csv('./train_dataset.csv.xls')\r\n",
    "\r\n",
    "print(trainingDf.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
      "0  LP001002   Male      No          0      Graduate            No   \n",
      "1  LP001003   Male     Yes          1      Graduate            No   \n",
      "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
      "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
      "4  LP001008   Male      No          0      Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5849                0.0         NaN             360.0   \n",
      "1             4583             1508.0       128.0             360.0   \n",
      "2             3000                0.0        66.0             360.0   \n",
      "3             2583             2358.0       120.0             360.0   \n",
      "4             6000                0.0       141.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area Loan_Status  \n",
      "0             1.0         Urban           Y  \n",
      "1             1.0         Rural           N  \n",
      "2             1.0         Urban           Y  \n",
      "3             1.0         Urban           Y  \n",
      "4             1.0         Urban           Y  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "print(\"============COLUMNS WITH EMPTY VALUE=============\")\r\n",
    "print(trainingDf.columns[trainingDf.isna().any()].tolist())\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============COLUMNS WITH EMPTY VALUE=============\n",
      "['Gender', 'Married', 'Dependents', 'Self_Employed', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "#Dropping loan_id\r\n",
    "trainingDf = trainingDf.drop(columns=['Loan_ID'])\r\n",
    "\r\n",
    "#Populating rows with null data with default values\r\n",
    "trainingDf['Gender'] = trainingDf['Gender'].fillna('unknown')\r\n",
    "trainingDf['Married'] = trainingDf['Married'].fillna('unknown')\r\n",
    "trainingDf['Self_Employed'] = trainingDf['Self_Employed'].fillna('unknown')\r\n",
    "trainingDf['Dependents'] = trainingDf['Dependents'].fillna(0)\r\n",
    "\r\n",
    "#Dropping rows with empty values for following columns 'LoanAmount', 'Loan_Amount_Term', 'Credit_History'\r\n",
    "trainingDf = trainingDf[trainingDf['LoanAmount'].notna()]\r\n",
    "trainingDf = trainingDf[trainingDf['Loan_Amount_Term'].notna()]\r\n",
    "trainingDf = trainingDf[trainingDf['Credit_History'].notna()]\r\n",
    "\r\n",
    "trainingDf['Dependents'].replace(\r\n",
    "    to_replace=['3+'],\r\n",
    "    value='4',\r\n",
    "    inplace=True\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "\r\n",
    "print(\"============COLUMNS WITH EMPTY VALUE=============\")\r\n",
    "print(trainingDf.columns[trainingDf.isna().any()].tolist())\r\n",
    "print(\"Remaining rows after dropping data:\", len(trainingDf.index))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============COLUMNS WITH EMPTY VALUE=============\n",
      "[]\n",
      "Remaining rows after dropping data: 529\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "print(\"============UNIQUE VALUE FOR CATEGORICAL DATA=============\")\r\n",
    "print(\"Gender: \", trainingDf['Gender'].unique())\r\n",
    "print(\"Married: \", trainingDf['Married'].unique())\r\n",
    "print(\"Education: \", trainingDf['Education'].unique())\r\n",
    "print(\"Self_Employed: \", trainingDf['Self_Employed'].unique())\r\n",
    "print(\"Property_Area: \", trainingDf['Property_Area'].unique())\r\n",
    "print('\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============UNIQUE VALUE FOR CATEGORICAL DATA=============\n",
      "Gender:  ['Male' 'Female' 'unknown']\n",
      "Married:  ['Yes' 'No' 'unknown']\n",
      "Education:  ['Graduate' 'Not Graduate']\n",
      "Self_Employed:  ['No' 'Yes' 'unknown']\n",
      "Property_Area:  ['Rural' 'Urban' 'Semiurban']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "from sklearn import preprocessing\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "\r\n",
    "train, test = train_test_split(trainingDf, test_size=0.2, random_state=23)\r\n",
    "print(train.head())\r\n",
    "X_train, y_train = train.copy().drop(columns=['Loan_Status']), train['Loan_Status']\r\n",
    "X_test, y_test = test.copy().drop(columns=['Loan_Status']), test['Loan_Status']\r\n",
    "\r\n",
    "Categorical_columns = [\"Gender\", \"Married\", \"Education\", \"Self_Employed\", \"Property_Area\"]\r\n",
    "Numerical_columns = [\"Dependents\", \"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"]\r\n",
    "\r\n",
    "Categorical_X_train = X_train[Categorical_columns]\r\n",
    "Categorical_X_test = X_test[Categorical_columns]\r\n",
    "\r\n",
    "Numerical_X_train = X_train[Numerical_columns]\r\n",
    "Numerical_X_test = X_test[Numerical_columns]\r\n",
    "\r\n",
    "encoder = preprocessing.OneHotEncoder()\r\n",
    "encoder.fit(Categorical_X_train)\r\n",
    "Categorical_X_train_encoded = encoder.transform(Categorical_X_train).toarray()\r\n",
    "Categorical_X_test_encoded = encoder.transform(Categorical_X_test).toarray()\r\n",
    "\r\n",
    "print(Numerical_X_train.head())\r\n",
    "\r\n",
    "standard_Scaler = preprocessing.MinMaxScaler()\r\n",
    "standard_Scaler.fit(Numerical_X_train)\r\n",
    "Numerical_X_train_encoded = standard_Scaler.transform(Numerical_X_train)\r\n",
    "Numerical_X_test_encoded = standard_Scaler.transform(Numerical_X_test)\r\n",
    "\r\n",
    "y_encoder = preprocessing.LabelEncoder()\r\n",
    "y_encoder.fit(y_train)\r\n",
    "Y_train_encoded = y_encoder.transform(y_train)\r\n",
    "Y_test_encoded = y_encoder.transform(y_test)\r\n",
    "\r\n",
    "Combined_X_train_encoded = np.concatenate((Categorical_X_train_encoded, Numerical_X_train_encoded), axis=1)\r\n",
    "#print(Combined_X_train_encoded)\r\n",
    "Combined_X_test_encoded = np.concatenate((Categorical_X_test_encoded, Numerical_X_test_encoded), axis=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Gender Married Dependents     Education Self_Employed  ApplicantIncome  \\\n",
      "330    Male      No          1      Graduate            No             4384   \n",
      "410  Female      No          1  Not Graduate           Yes             3867   \n",
      "217    Male     Yes          0      Graduate            No             3727   \n",
      "143    Male     Yes          0      Graduate            No             2698   \n",
      "525    Male     Yes          2      Graduate           Yes            17500   \n",
      "\n",
      "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
      "330             1793.0       117.0             360.0             1.0   \n",
      "410                0.0        62.0             360.0             1.0   \n",
      "217             1775.0       131.0             360.0             1.0   \n",
      "143             2034.0       122.0             360.0             1.0   \n",
      "525                0.0       400.0             360.0             1.0   \n",
      "\n",
      "    Property_Area Loan_Status  \n",
      "330         Urban           Y  \n",
      "410     Semiurban           N  \n",
      "217     Semiurban           Y  \n",
      "143     Semiurban           Y  \n",
      "525         Rural           Y  \n",
      "    Dependents  ApplicantIncome  CoapplicantIncome  LoanAmount  \\\n",
      "330          1             4384             1793.0       117.0   \n",
      "410          1             3867                0.0        62.0   \n",
      "217          0             3727             1775.0       131.0   \n",
      "143          0             2698             2034.0       122.0   \n",
      "525          2            17500                0.0       400.0   \n",
      "\n",
      "     Loan_Amount_Term  Credit_History  \n",
      "330             360.0             1.0  \n",
      "410             360.0             1.0  \n",
      "217             360.0             1.0  \n",
      "143             360.0             1.0  \n",
      "525             360.0             1.0  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Logistic Regression Model\r\n",
    "\r\n",
    "Logistic Regression model is a predictive analysis and is a good fit for loan prediction because we want to predict a binary outcome: approved/not approved. Through encoding,\r\n",
    "the output is mapped as either 0 or 1. That means that we want to analyze the relationship between one dependent variable (the loan status) and multiple independent variable which are either categorical or numerical.This type of model solves the problem by using a logarithmic transformation on the dependent variable, allowing expression of linear regression in a logarithmic mode."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "#model using Logistic Regression\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\r\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "print(\"============LOGISTIC REGRESSION MODEL=============\")\r\n",
    "lr_model = LogisticRegression()\r\n",
    "lr_model.fit(Combined_X_train_encoded,Y_train_encoded)\r\n",
    "y_predicted = lr_model.predict(Combined_X_test_encoded)\r\n",
    "print(\"Accuracy is \", accuracy_score(y_predicted,Y_test_encoded))\r\n",
    "print(\"Mean Square Error : \", mean_squared_error(Y_test_encoded, y_predicted))\r\n",
    "print(confusion_matrix(y_predicted,Y_test_encoded))\r\n",
    "print(\"Classification Report : \")\r\n",
    "print(classification_report(Y_test_encoded, y_predicted))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============LOGISTIC REGRESSION MODEL=============\n",
      "Accuracy is  0.8207547169811321\n",
      "Mean Square Error :  0.1792452830188679\n",
      "[[23  0]\n",
      " [19 64]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71        42\n",
      "           1       0.77      1.00      0.87        64\n",
      "\n",
      "    accuracy                           0.82       106\n",
      "   macro avg       0.89      0.77      0.79       106\n",
      "weighted avg       0.86      0.82      0.81       106\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) 10-fold cross validation to generalize the Logistic Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# To find list of accuracy and MSE values of the model using K-fold cross validation\r\n",
    "\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "\r\n",
    "print(\"============LOGISTIC REGRESSION MODEL USING 10-FOLD CROSS VALIDATION=============\")\r\n",
    "kf = KFold(n_splits=10)\r\n",
    "X = trainingDf.copy().drop(columns=['Loan_Status'])\r\n",
    "y = trainingDf['Loan_Status']\r\n",
    "\r\n",
    "#re-split the processed data into X and y then encode before doing 10-cross validation\r\n",
    "Categorical_X = X[Categorical_columns]\r\n",
    "#print(Categorical_X)\r\n",
    "Numerical_X = X[Numerical_columns]\r\n",
    "\r\n",
    "encoder = preprocessing.OneHotEncoder()\r\n",
    "encoder.fit(Categorical_X)\r\n",
    "Categorical_X_encoded = encoder.transform(Categorical_X).toarray()\r\n",
    "\r\n",
    "#print(Categorical_X_encoded)\r\n",
    "\r\n",
    "standard_Scaler.fit(Numerical_X)\r\n",
    "Numerical_X_encoded = standard_Scaler.transform(Numerical_X)\r\n",
    "#print(Numerical_X_encoded)\r\n",
    "\r\n",
    "y_encoder.fit(y)\r\n",
    "Y_encoded = y_encoder.transform(y)\r\n",
    "\r\n",
    "Combined_X_encoded = np.concatenate((Categorical_X_encoded, Numerical_X_encoded), axis=1)\r\n",
    "\r\n",
    "#print(Combined_X_encoded)\r\n",
    "\r\n",
    "idx = 0\r\n",
    "for train_indices, test_indices in kf.split(Combined_X_encoded):\r\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\r\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\r\n",
    "    \r\n",
    "    lr_model.fit(Combined_X_encoded[start_train:stop_train], Y_encoded[start_train:stop_train])\r\n",
    "    pred = lr_model.predict(Combined_X_encoded[start_test:stop_test])\r\n",
    "\r\n",
    "    idx+=1\r\n",
    "    print(\"Accuracy for batch \", idx, \" : \", accuracy_score(Y_encoded[start_test:stop_test], pred))\r\n",
    "    print(\"Mean Square Error for batch \", idx, \" : \", mean_squared_error(Y_encoded[start_test:stop_test], pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============LOGISTIC REGRESSION MODEL USING 10-FOLD CROSS VALIDATION=============\n",
      "Accuracy for batch  1  :  0.7735849056603774\n",
      "Mean Square Error for batch  1  :  0.22641509433962265\n",
      "Accuracy for batch  2  :  0.8490566037735849\n",
      "Mean Square Error for batch  2  :  0.1509433962264151\n",
      "Accuracy for batch  3  :  0.7547169811320755\n",
      "Mean Square Error for batch  3  :  0.24528301886792453\n",
      "Accuracy for batch  4  :  0.7735849056603774\n",
      "Mean Square Error for batch  4  :  0.22641509433962265\n",
      "Accuracy for batch  5  :  0.8301886792452831\n",
      "Mean Square Error for batch  5  :  0.16981132075471697\n",
      "Accuracy for batch  6  :  0.7547169811320755\n",
      "Mean Square Error for batch  6  :  0.24528301886792453\n",
      "Accuracy for batch  7  :  0.8490566037735849\n",
      "Mean Square Error for batch  7  :  0.1509433962264151\n",
      "Accuracy for batch  8  :  0.8679245283018868\n",
      "Mean Square Error for batch  8  :  0.1320754716981132\n",
      "Accuracy for batch  9  :  0.8301886792452831\n",
      "Mean Square Error for batch  9  :  0.16981132075471697\n",
      "Accuracy for batch  10  :  0.8653846153846154\n",
      "Mean Square Error for batch  10  :  0.1346153846153846\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3) Naïve Bayes Classifier for Numerical Attributes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "#Calssify using Naive Bayes for numerical attributes \r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.metrics import classification_report \r\n",
    "\r\n",
    "print(\"============NAIVE BAYES CLASSIFIER FOR NUMERICAL ATTRIBUTES=============\")\r\n",
    "\r\n",
    "GNB = GaussianNB()\r\n",
    "\r\n",
    "GNB.fit(Numerical_X_train_encoded, Y_train_encoded)\r\n",
    "\r\n",
    "print(\"Classification report for train datasets:\")\r\n",
    "print(classification_report(Y_train_encoded, GNB.predict(Numerical_X_train_encoded)))\r\n",
    "print(\"***************************************************************************\")\r\n",
    "print(\"Classification report for test datasets:\")\r\n",
    "print(classification_report(Y_test_encoded, GNB.predict(Numerical_X_test_encoded)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============NAIVE BAYES CLASSIFIER FOR NUMERICAL ATTRIBUTES=============\n",
      "Classification report for train datasets:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.47      0.58       121\n",
      "           1       0.82      0.94      0.88       302\n",
      "\n",
      "    accuracy                           0.81       423\n",
      "   macro avg       0.79      0.71      0.73       423\n",
      "weighted avg       0.80      0.81      0.79       423\n",
      "\n",
      "***************************************************************************\n",
      "Classification report for test datasets:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.55      0.69        42\n",
      "           1       0.77      0.97      0.86        64\n",
      "\n",
      "    accuracy                           0.80       106\n",
      "   macro avg       0.84      0.76      0.77       106\n",
      "weighted avg       0.83      0.80      0.79       106\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4) 10-fold cross validation to generalize the Naïve Bayes Classifier for Numerical Attributes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "# To find list of accuracy and MSE values of the model using K-fold cross validation\r\n",
    "\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "\r\n",
    "kf = KFold(n_splits=10)\r\n",
    "\r\n",
    "print(\"============NAIVE BAYES CLASSIFIER FOR NUMERICAL ATTRIBUTES USING 10-FOLD CROSS VALIDATION=============\")\r\n",
    "\r\n",
    "idx = 0\r\n",
    "for train_indices, test_indices in kf.split(Numerical_X__encoded):\r\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\r\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\r\n",
    "    \r\n",
    "    GNB.fit(Numerical_X__encoded[start_train:stop_train], Y_encoded[start_train:stop_train])\r\n",
    "    pred = GNB.predict(Numerical_X__encoded[start_test:stop_test])\r\n",
    "\r\n",
    "    idx+=1\r\n",
    "    print(\"Accuracy for batch \", idx, \" : \", accuracy_score(Y_encoded[start_test:stop_test], pred))\r\n",
    "    print(\"Mean Square Error for batch \", idx, \" : \", mean_squared_error(Y_encoded[start_test:stop_test], pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============NAIVE BAYES CLASSIFIER FOR NUMERICAL ATTRIBUTES USING 10-FOLD CROSS VALIDATION=============\n",
      "Accuracy for batch  1  :  0.7547169811320755\n",
      "Mean Square Error for batch  1  :  0.24528301886792453\n",
      "Accuracy for batch  2  :  0.8490566037735849\n",
      "Mean Square Error for batch  2  :  0.1509433962264151\n",
      "Accuracy for batch  3  :  0.7547169811320755\n",
      "Mean Square Error for batch  3  :  0.24528301886792453\n",
      "Accuracy for batch  4  :  0.7547169811320755\n",
      "Mean Square Error for batch  4  :  0.24528301886792453\n",
      "Accuracy for batch  5  :  0.8113207547169812\n",
      "Mean Square Error for batch  5  :  0.18867924528301888\n",
      "Accuracy for batch  6  :  0.7547169811320755\n",
      "Mean Square Error for batch  6  :  0.24528301886792453\n",
      "Accuracy for batch  7  :  0.8301886792452831\n",
      "Mean Square Error for batch  7  :  0.16981132075471697\n",
      "Accuracy for batch  8  :  0.8490566037735849\n",
      "Mean Square Error for batch  8  :  0.1509433962264151\n",
      "Accuracy for batch  9  :  0.8113207547169812\n",
      "Mean Square Error for batch  9  :  0.18867924528301888\n",
      "Accuracy for batch  10  :  0.8461538461538461\n",
      "Mean Square Error for batch  10  :  0.15384615384615385\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5) Naïve Bayes Classifier for Categorical Attributes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.naive_bayes import CategoricalNB\r\n",
    "\r\n",
    "print(\"============NAIVE BAYES CLASSIFIER FOR CATEGORICAL ATTRIBUTES=============\")\r\n",
    "\r\n",
    "NB = CategoricalNB() \r\n",
    "\r\n",
    "NB.fit(Categorical_X_train_encoded, Y_train_encoded)\r\n",
    "print(classification_report(Y_test_encoded, NB.predict(Categorical_X_test_encoded)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============NAIVE BAYES CLASSIFIER FOR CATEGORICAL ATTRIBUTES=============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.19      0.27        42\n",
      "           1       0.62      0.86      0.72        64\n",
      "\n",
      "    accuracy                           0.59       106\n",
      "   macro avg       0.54      0.52      0.50       106\n",
      "weighted avg       0.56      0.59      0.54       106\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6) 10-fold cross validation to generalize the Naïve Bayes Classifier for Categorical Attributes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "from sklearn.model_selection import KFold\r\n",
    "\r\n",
    "print(\"============NAIVE BAYES CLASSIFIER FOR CATEGORICAL ATTRIBUTES USING 10-FOLD CROSS VALIDATION=============\")\r\n",
    "\r\n",
    "kf = KFold(n_splits=10)\r\n",
    "\r\n",
    "idx = 0\r\n",
    "for train_indices, test_indices in kf.split(Categorical_X_encoded):\r\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\r\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\r\n",
    "    \r\n",
    "    GNB.fit(Categorical_X_encoded[start_train:stop_train], Y_encoded[start_train:stop_train])\r\n",
    "    pred = GNB.predict(Categorical_X_encoded[start_test:stop_test])\r\n",
    "\r\n",
    "    idx+=1\r\n",
    "    print(\"Accuracy for batch \", idx, \" : \", accuracy_score(Y_encoded[start_test:stop_test], pred))\r\n",
    "    print(\"Mean Square Error for batch \", idx, \" : \", mean_squared_error(Y_encoded[start_test:stop_test], pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============NAIVE BAYES CLASSIFIER FOR CATEGORICAL ATTRIBUTES USING 10-FOLD CROSS VALIDATION=============\n",
      "Accuracy for batch  1  :  0.41509433962264153\n",
      "Mean Square Error for batch  1  :  0.5849056603773585\n",
      "Accuracy for batch  2  :  0.2830188679245283\n",
      "Mean Square Error for batch  2  :  0.7169811320754716\n",
      "Accuracy for batch  3  :  0.41509433962264153\n",
      "Mean Square Error for batch  3  :  0.5849056603773585\n",
      "Accuracy for batch  4  :  0.2830188679245283\n",
      "Mean Square Error for batch  4  :  0.7169811320754716\n",
      "Accuracy for batch  5  :  0.3018867924528302\n",
      "Mean Square Error for batch  5  :  0.6981132075471698\n",
      "Accuracy for batch  6  :  0.3584905660377358\n",
      "Mean Square Error for batch  6  :  0.6415094339622641\n",
      "Accuracy for batch  7  :  0.37735849056603776\n",
      "Mean Square Error for batch  7  :  0.6226415094339622\n",
      "Accuracy for batch  8  :  0.33962264150943394\n",
      "Mean Square Error for batch  8  :  0.660377358490566\n",
      "Accuracy for batch  9  :  0.32075471698113206\n",
      "Mean Square Error for batch  9  :  0.6792452830188679\n",
      "Accuracy for batch  10  :  0.34615384615384615\n",
      "Mean Square Error for batch  10  :  0.6538461538461539\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "7cae688b6d5c7886c97c16c08b8426e0c75b8da6e1119f020936594eaecaf1a0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}